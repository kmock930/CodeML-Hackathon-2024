{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d77573",
   "metadata": {},
   "source": [
    "# Challenge: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38305289",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b392743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch;\n",
    "from torch import nn;\n",
    "import numpy;\n",
    "import matplotlib.pyplot as plt;\n",
    "import pandas as pd;\n",
    "import sklearn;\n",
    "\n",
    "from ForwardModelNN import FeedForwardNN;\n",
    "\n",
    "device: str = \"cuda\"  if torch.cuda.is_available() else \"cpu\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a31b02",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbb95f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d191e",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7358b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/participant_data_cleaned_median.csv');\n",
    "column_names = df.columns;\n",
    "for col in column_names: print(\"Feature: \" + col);\n",
    "\n",
    "df['_time'] = pd.to_datetime(df['_time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab54351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import random;\n",
    "origData = df.to_numpy();\n",
    "randSample = origData[random.randint(0,len(origData)-1)]; # for inspection\n",
    "\n",
    "print(\"Type of Array with original data: \" + str(type(origData)));\n",
    "print(\"Type of a record in the original data: \" + str(type(randSample)));\n",
    "print(\"Number of records in the original dataset: \" + str(len(origData)));\n",
    "print(\"Number of features in a record: \" + str(randSample.size));\n",
    "print(\"Dimensionality of a record: \" + str(randSample.ndim));\n",
    "print(\"Dimensionality of the entire data array: \" + str(origData.ndim));\n",
    "print(\"Shape of the Array: \" + str(origData.shape));\n",
    "print(\"Shape of a record: \" + str(randSample.shape));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d68dc6",
   "metadata": {},
   "source": [
    "We saw NaN values in the table. That is because of empty cells in the table. To prove our intuition, let's inspect whether there are NaN in specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d1455",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b322b2",
   "metadata": {},
   "source": [
    "We need to replace all the NaN values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c83b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure there is no more NaN values in the table\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a5148",
   "metadata": {},
   "source": [
    "Now there's no more NaN values in table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01015d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random;\n",
    "origData = df.to_numpy();\n",
    "randSample = origData[random.randint(0,len(origData)-1)]; # for inspection\n",
    "\n",
    "print(\"Type of Array with original data: \" + str(type(origData)));\n",
    "print(\"Type of a record in the original data: \" + str(type(randSample)));\n",
    "print(\"Number of records in the original dataset: \" + str(len(origData)));\n",
    "print(\"Number of features in a record: \" + str(randSample.size));\n",
    "print(\"Dimensionality of a record: \" + str(randSample.ndim));\n",
    "print(\"Dimensionality of the entire data array: \" + str(origData.ndim));\n",
    "print(\"Shape of the Array: \" + str(origData.shape));\n",
    "print(\"Shape of a record: \" + str(randSample.shape));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4462fb0",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e8df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd85763b",
   "metadata": {},
   "source": [
    "## Splitting the Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79497a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# From web\n",
    "def create_window(target, feature, window=1, offset=0):\n",
    "    feature_new, target_new = [], []\n",
    "    feature_np = feature.to_numpy()\n",
    "    target_np = target.to_numpy()\n",
    "    for i in range(window, target.shape[0] - offset):\n",
    "        feature_list = feature_np[i - window:i]\n",
    "        feature_new.append(feature_list.reshape(window, feature_np.shape[1]))\n",
    "        target_new.append(target_np[i+offset].reshape(1))\n",
    "    return np.array(feature_new), np.array(target_new)\n",
    "\n",
    "# Scale all except date\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df.drop(columns='_time'))\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.drop(columns='_time').columns)\n",
    "\n",
    "window = 30\n",
    "feature_columns = [\"Latitude\", \"Longitude\", \"Altitude\", 'http_result', 'icmp_result', 'tcp_result', 'udp_result']\n",
    "\n",
    "feature, target = create_window(df_scaled['http_result'],df_scaled[feature_columns], window=window)\n",
    "\n",
    "print(feature[0])\n",
    "print(target[0])\n",
    "print(df_scaled.head(12))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bfe9e1",
   "metadata": {},
   "source": [
    "# Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a777d9b",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd688d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.LSTM(64, input_shape=[x_train.shape[1], x_train.shape[2]]),\n",
    "    layers.Dense(1)])\n",
    "\n",
    "model.compile(\n",
    "    # optimizer=tf.keras.optimizers.RMSprop(0.0001),\n",
    "    optimizer='RMSProp', \n",
    "    loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4e806",
   "metadata": {},
   "source": [
    "## Fitting the Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd044bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.3,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8e61d9",
   "metadata": {},
   "source": [
    "## Verify if Fitting is performed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e455ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eeca1b0",
   "metadata": {},
   "source": [
    "# Perform Predictions with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f082b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5d8a875",
   "metadata": {},
   "source": [
    "# Evaluate the Performance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fa0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc0f1048",
   "metadata": {},
   "source": [
    "# Conclusion and Further Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a63520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
